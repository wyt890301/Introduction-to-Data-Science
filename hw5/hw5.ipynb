{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引用packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料前處理\n",
    "# 讀取train_data(正式版)\n",
    "train_data = pd.read_csv('./data/train.csv') \n",
    "\n",
    "# 將連續型資料標準化並傳回train_data \n",
    "train_standard = train_data[['CreditScore', 'Balance', 'EstimatedSalary']]\n",
    "z_scaler = StandardScaler()\n",
    "# z_scaler = Normalizer()\n",
    "z_scaler.fit(train_standard)\n",
    "train_standard_scaled = z_scaler.transform(train_standard)\n",
    "train_standard_scaled = pd.DataFrame(train_standard_scaled, columns=['CreditScore', 'Balance', 'EstimatedSalary'])\n",
    "train_data['Balance'] = train_standard_scaled['Balance']\n",
    "train_data['EstimatedSalary'] = train_standard_scaled['EstimatedSalary']\n",
    "train_data['CreditScore'] = train_standard_scaled['CreditScore']\n",
    "\n",
    "train_features = train_data\n",
    "#去除超過3個標準差的離群值(全部經標準化欄位)\n",
    "# train_features = train_data[abs(train_data['CreditScore'])<3]\n",
    "# train_features = train_features[abs(train_features['Balance'])<3]\n",
    "# train_features = train_features[abs(train_features['EstimatedSalary'])<3]\n",
    "\n",
    "# 將非數值資料轉換為數值\n",
    "train_features_drop = train_features.drop(['RowNumber','CustomerId', 'Surname', 'Exited'],axis=1)\n",
    "train_features_sub = pd.get_dummies(train_features_drop)\n",
    "\n",
    "# 建立train_data的類別值與資料\n",
    "train_data_class = train_features['Exited'].values \n",
    "train_data_sub = train_features_sub.values\n",
    "\n",
    "\n",
    "# 讀取test_data\n",
    "test_data = pd.read_csv('./data/test.csv') \n",
    "\n",
    "# 將連續型資料標準化並傳回test_data \n",
    "test_standard = test_data[['CreditScore', 'Balance', 'EstimatedSalary']]\n",
    "test_standard_scaled = z_scaler.transform(test_standard)\n",
    "test_standard_scaled = pd.DataFrame(test_standard_scaled, columns=['CreditScore', 'Balance', 'EstimatedSalary'])\n",
    "test_data['Balance']  = test_standard_scaled['Balance']\n",
    "test_data['EstimatedSalary']  = test_standard_scaled['EstimatedSalary']\n",
    "test_data['CreditScore']  = test_standard_scaled['CreditScore']\n",
    "\n",
    "# 將非數值資料轉換為數值\n",
    "test_features = test_data.drop(['RowNumber','CustomerId', 'Surname'],axis=1)\n",
    "test_features_sub = pd.get_dummies(test_features)\n",
    "test_data_sub = test_features_sub.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7276699275362319, 3, 0.7187311564407896, 6, 0.7034474115436802, 7]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 從train_data中切訓練資料\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_data_sub, train_data_class, \n",
    "                                                    train_size=0.75, \n",
    "                                                    random_state=123)\n",
    "\n",
    "# 利用SMOTE維持class數量的平衡\n",
    "# resampled_x, resampled_y = SMOTE(random_state=42).fit_resample(train_x, train_y)\n",
    "\n",
    "# 利用遞迴找到 max_depth最佳參數\n",
    "max_parameters=[0,0,0,0,0,0]\n",
    "for x in range(3,11):\n",
    "    \n",
    "    # 建立 XGBClassifier 模型\n",
    "    xgb_Model = XGBClassifier(n_estimators=200, max_depth= x, use_label_encoder =False, eval_metric=\"error\")\n",
    "    outcomes = xgb_Model.fit(train_x, train_y).predict(test_x)\n",
    "#     outcomes = xgb_Model.fit(resampled_x, resampled_y).predict(test_x)\n",
    "\n",
    "    # 計算Accuracy, Precision & Recall\n",
    "    accuracy = xgb_Model.score(test_x, test_y)\n",
    "    precision = precision_score(test_y, outcomes, average='binary')\n",
    "    recall = recall_score(test_y, outcomes, average=None)\n",
    "    f_score = (2*precision*recall[1]) / (precision+recall[1])\n",
    "    score = 0.3*accuracy + 0.3*precision + 0.4*f_score\n",
    "\n",
    "    if score > max_parameters[0]:\n",
    "        max_parameters[0] = score \n",
    "        max_parameters[1] = x \n",
    "    elif score > max_parameters[2]:\n",
    "        max_parameters[2] = score \n",
    "        max_parameters[3] = x\n",
    "    elif score > max_parameters[4]:\n",
    "        max_parameters[4] = score \n",
    "        max_parameters[5] = x\n",
    "        \n",
    "print(max_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 建立 XGBClassifier 模型\n",
    "xgb_Model = XGBClassifier(n_estimators=200, max_depth= 3, use_label_encoder =False, eval_metric=\"error\")\n",
    "outcomes = xgb_Model.fit(train_data_sub, train_data_class).predict(test_data_sub)\n",
    "# resampled_x, resampled_y = SMOTE().fit_resample(train_data_sub, train_data_class)\n",
    "# outcomes = xgb_Model.fit(resampled_x, resampled_y).predict(test_data_sub)\n",
    "print(outcomes.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(hidden_layer_sizes=(30,10,2),random_state=0)\n",
    "nn.fit(train_data_sub, train_data_class)\n",
    "outcomes = nn.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(train_data_sub, train_data_class)\n",
    "outcomes = classifier.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "knc.fit(train_data_sub, train_data_class)\n",
    "outcomes = knc.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_data_sub, train_data_class)\n",
    "outcomes = classifier.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料寫入csv檔\n",
    "test_data_class = pd.Series(outcomes)\n",
    "test_df = pd.DataFrame({'RowNumber':test_data['RowNumber'], 'Exited':test_data_class})\n",
    "test_df.to_csv('./data/xgboost(200&3).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
